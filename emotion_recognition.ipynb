{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9HE7XHtp44X"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80skWkBko5qr",
        "outputId": "33621790-d180-49ee-eb2e-d97c6be4b112"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 22968 images belonging to 7 classes.\n",
            "Found 5741 images belonging to 7 classes.\n",
            "Found 7178 images belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "training_dir = 'train'\n",
        "test_dir = 'test'\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    # rotation_range=20,\n",
        "    # shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.2\n",
        ")\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(training_dir, target_size=(48, 48), color_mode='grayscale', class_mode='categorical', batch_size=64, subset='training')\n",
        "validation_generator = train_datagen.flow_from_directory(training_dir, target_size=(48, 48), color_mode='grayscale', class_mode='categorical', batch_size=64, subset='validation')\n",
        "test_generator = test_datagen.flow_from_directory(test_dir, target_size=(48, 48), color_mode='grayscale', class_mode='categorical', batch_size=64)\n",
        "\n",
        "label_map = (train_generator.class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-_qK8PJfThZ"
      },
      "outputs": [],
      "source": [
        "class myCallBack(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('accuracy')>0.95):\n",
        "            print(\"\\nReached 95% accuracy so cancelling training!\")\n",
        "            self.model.stop_training = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOHnK9HvIfFX"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32 ,(3, 3), activation='relu', input_shape=(48, 48, 1), kernel_regularizer=l2(0.01)),\n",
        "    Conv2D(32 ,(3, 3), activation='relu', kernel_regularizer=l2(0.01)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.01)),\n",
        "    Conv2D(64 ,(3, 3), activation='relu', kernel_regularizer=l2(0.01)),\n",
        "    BatchNormalization(),\n",
        "    # MaxPooling2D((2, 2)),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    # Conv2D(128 ,(3, 3), activation='relu'),\n",
        "    # BatchNormalization(),\n",
        "    # # MaxPooling2D((2, 2)),\n",
        "    # Dropout(0.25),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu', kernel_regularizer=l2(0.01)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.2),\n",
        "    # Dense(128, activation='relu'),\n",
        "    # BatchNormalization(),\n",
        "    # Dropout(0.4),\n",
        "\n",
        "    Dense(7, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MR5B_ZXB8gyQ",
        "outputId": "de7be7f2-3c51-4e27-b477-7f14ea013fc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_318 (Conv2D)         (None, 46, 46, 32)        320       \n",
            "                                                                 \n",
            " conv2d_319 (Conv2D)         (None, 44, 44, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_308 (Ba  (None, 44, 44, 32)       128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_27 (MaxPoolin  (None, 22, 22, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 22, 22, 32)        0         \n",
            "                                                                 \n",
            " conv2d_320 (Conv2D)         (None, 20, 20, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_321 (Conv2D)         (None, 18, 18, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_309 (Ba  (None, 18, 18, 64)       256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 18, 18, 64)        0         \n",
            "                                                                 \n",
            " flatten_11 (Flatten)        (None, 20736)             0         \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 256)               5308672   \n",
            "                                                                 \n",
            " batch_normalization_310 (Ba  (None, 256)              1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 7)                 1799      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,376,871\n",
            "Trainable params: 5,376,167\n",
            "Non-trainable params: 704\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LRWvPQQj_1j"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer = Adam(learning_rate=0.0001), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "id": "BLqN4wJ6kHrb",
        "outputId": "bdb33297-6fe7-412f-9337-ad8ad643be2a"
      },
      "outputs": [],
      "source": [
        "model.fit(train_generator, epochs=100, validation_data=validation_generator, callbacks=[myCallBack()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZzD7U4tpU9G"
      },
      "outputs": [],
      "source": [
        "model.evaluate(test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QreRzZpl-uLH"
      },
      "outputs": [],
      "source": [
        "def url_to_image(url):\n",
        "\tresp = urllib.request.urlopen(url)\n",
        "\timage = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "\timage = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        "\treturn image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1Ob51X_qoiF"
      },
      "outputs": [],
      "source": [
        "classifier_dir = 'haarcascade_frontalface_default.xml'\n",
        "face_classifier = cv2.CascadeClassifier(classifier_dir)\n",
        "\n",
        "def predict(url):\n",
        "    img = url_to_image(url)\n",
        "    faces = face_classifier.detectMultiScale(img, 1.3, 5)\n",
        "\n",
        "    for (x,y,w,h) in faces:\n",
        "        cv2.rectangle(img, (x,y), (x+w,y+h), (255,0,0), 2)\n",
        "        roi_img = img[y:y+h, x:x+w]\n",
        "        roi_img = cv2.resize(roi_img, (48, 48), interpolation=cv2.INTER_AREA)\n",
        "        roi_img = cv2.cvtColor(roi_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        if np.sum([roi_img])!=0:\n",
        "            roi = roi_img.astype('float')/255.0\n",
        "            roi = img_to_array(roi)\n",
        "            roi = np.expand_dims(roi,axis=0)\n",
        "\n",
        "            preds = np.argmax(model.predict(roi))\n",
        "            label= list(label_map.keys())[list(label_map.values()).index(preds)]\n",
        "            label_position = (x,y)\n",
        "            cv2.putText(img, label, label_position, cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "        else:\n",
        "            cv2.putText(img, 'No Face Found', (20, 60), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 3)\n",
        "    return img"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Input the URL link of the test image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emLvRcJh_j1x"
      },
      "outputs": [],
      "source": [
        "url = input()\n",
        "predict_img = predict(url)\n",
        "plt.imshow(predict_img[:,:,::-1])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
